{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## simple but good LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gidi: seems like this guy first does the standard tokenizing, encoding, padding stuff\n",
    "'''\n",
    "Single model may achieve LB scores at around 0.29+ ~ 0.30+\n",
    "Average ensembles can easily get 0.28+ or less\n",
    "Don't need to be an expert of feature engineering\n",
    "All you need is a GPU!!!!!!!\n",
    "\n",
    "The code is tested on Keras 2.0.0 using Tensorflow backend, and Python 2.7\n",
    "\n",
    "According to experiments by kagglers, Theano backend with GPU may give bad LB scores while\n",
    "        the val_loss seems to be fine, so try Tensorflow backend first please\n",
    "'''\n",
    "\n",
    "########################################\n",
    "## import packages\n",
    "########################################\n",
    "import os\n",
    "import re\n",
    "import csv\n",
    "import codecs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from string import punctuation\n",
    "\n",
    "from gensim.models import KeyedVectors\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation\n",
    "#from keras.layers.merge import concatenate # keras 2.0\n",
    "from keras.layers import merge\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "import sys\n",
    "#reload(sys)\n",
    "#sys.setdefaultencoding('utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def do_clip(arr, mx):\n",
    "    clipped = np.clip(arr, (1-mx)/1, mx)\n",
    "    return clipped/clipped.sum(axis=1)[:, np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "## set directories and parameters\n",
    "########################################\n",
    "BASE_DIR = '../input/'\n",
    "EMBEDDING_FILE = BASE_DIR + 'GoogleNews-vectors-negative300.bin'\n",
    "TRAIN_DATA_FILE = '/mnt/quora_kaggle/train.csv'\n",
    "TEST_DATA_FILE = '/mnt/quora_kaggle/test.csv'\n",
    "MAX_SEQUENCE_LENGTH = 30\n",
    "MAX_NB_WORDS = 200000\n",
    "EMBEDDING_DIM = 300\n",
    "VALIDATION_SPLIT = 0.1\n",
    "\n",
    "num_lstm = np.random.randint(175, 275)\n",
    "num_dense = np.random.randint(100, 150)\n",
    "rate_drop_lstm = 0.15 + np.random.rand() * 0.25\n",
    "rate_drop_dense = 0.15 + np.random.rand() * 0.25\n",
    "\n",
    "act = 'relu'\n",
    "re_weight = True # whether to re-weight classes to fit the 17.5% share in test set\n",
    "\n",
    "STAMP = 'lstm_%d_%d_%.2f_%.2f'%(num_lstm, num_dense, rate_drop_lstm, \\\n",
    "        rate_drop_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n########################################\\n## index word vectors\\n########################################\\nprint('Indexing word vectors')\\n\\nword2vec = KeyedVectors.load_word2vec_format(EMBEDDING_FILE,         binary=True)\\nprint('Found %s word vectors of word2vec' % len(word2vec.vocab))\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "########################################\n",
    "## index word vectors\n",
    "########################################\n",
    "print('Indexing word vectors')\n",
    "\n",
    "word2vec = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, \\\n",
    "        binary=True)\n",
    "print('Found %s word vectors of word2vec' % len(word2vec.vocab))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     7
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing text dataset\n",
      "Found 404290 texts in train.csv\n",
      "Found 2345796 texts in test.csv\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "## process texts in datasets\n",
    "########################################\n",
    "print('Processing text dataset')\n",
    "\n",
    "# The function \"text_to_wordlist\" is from\n",
    "# https://www.kaggle.com/currie32/quora-question-pairs/the-importance-of-cleaning-text\n",
    "def text_to_wordlist(text, remove_stopwords=False, stem_words=False):\n",
    "    # Clean the text, with the option to remove stopwords and to stem words.\n",
    "    \n",
    "    # Convert words to lower case and split them\n",
    "    text = text.lower().split()\n",
    "\n",
    "    # Optionally, remove stop words\n",
    "    if remove_stopwords:\n",
    "        stops = set(stopwords.words(\"english\"))\n",
    "        text = [w for w in text if not w in stops]\n",
    "    \n",
    "    text = \" \".join(text)\n",
    "\n",
    "    # Clean the text\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" - \", text)\n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    \n",
    "    # Optionally, shorten words to their stems\n",
    "    if stem_words:\n",
    "        text = text.split()\n",
    "        stemmer = SnowballStemmer('english')\n",
    "        stemmed_words = [stemmer.stem(word) for word in text]\n",
    "        text = \" \".join(stemmed_words)\n",
    "    \n",
    "    # Return a list of words\n",
    "    return(text)\n",
    "\n",
    "texts_1 = [] \n",
    "texts_2 = []\n",
    "labels = []\n",
    "with codecs.open(TRAIN_DATA_FILE, encoding='utf-8') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    header = next(reader)\n",
    "    for values in reader:\n",
    "        texts_1.append(text_to_wordlist(values[3]))\n",
    "        texts_2.append(text_to_wordlist(values[4]))\n",
    "        labels.append(int(values[5]))\n",
    "print('Found %s texts in train.csv' % len(texts_1))\n",
    "\n",
    "test_texts_1 = []\n",
    "test_texts_2 = []\n",
    "test_ids = []\n",
    "with codecs.open(TEST_DATA_FILE, encoding='utf-8') as f:\n",
    "    reader = csv.reader(f, delimiter=',')\n",
    "    header = next(reader)\n",
    "    for values in reader:\n",
    "        test_texts_1.append(text_to_wordlist(values[1]))\n",
    "        test_texts_2.append(text_to_wordlist(values[2]))\n",
    "        test_ids.append(values[0])\n",
    "print('Found %s texts in test.csv' % len(test_texts_1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 120499 unique tokens\n",
      "Shape of data tensor: (404290, 30)\n",
      "Shape of label tensor: (404290,)\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(nb_words=MAX_NB_WORDS) #nb_words in keras 2.0\n",
    "tokenizer.fit_on_texts(texts_1 + texts_2 + test_texts_1 + test_texts_2)\n",
    "\n",
    "sequences_1 = tokenizer.texts_to_sequences(texts_1)\n",
    "sequences_2 = tokenizer.texts_to_sequences(texts_2)\n",
    "test_sequences_1 = tokenizer.texts_to_sequences(test_texts_1)\n",
    "test_sequences_2 = tokenizer.texts_to_sequences(test_texts_2)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens' % len(word_index))\n",
    "\n",
    "data_1 = pad_sequences(sequences_1, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "data_2 = pad_sequences(sequences_2, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "labels = np.array(labels)\n",
    "print('Shape of data tensor:', data_1.shape)\n",
    "print('Shape of label tensor:', labels.shape)\n",
    "\n",
    "test_data_1 = pad_sequences(test_sequences_1, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "test_data_2 = pad_sequences(test_sequences_2, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "test_ids = np.array(test_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#gidi: my w2v\n",
    "import bcolz\n",
    "import pickle\n",
    "import re\n",
    "def load_array(fname):\n",
    "    return bcolz.open(fname)[:]\n",
    "\n",
    "def load_vectors(loc):\n",
    "    return (load_array(loc+'.dat'),\n",
    "        pickle.load(open(loc+'_words.pkl','rb'),encoding='latin1'),\n",
    "        pickle.load(open(loc+'_idx.pkl','rb'),encoding='latin1'))\n",
    "\n",
    "#load word vecs\n",
    "vec_size=300 #glove has 50,100,200,300\n",
    "vecs, words, wordidx = load_vectors('/mnt/glove/6B.'+str(vec_size)+'d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v(w): return vecs[wordidx[w]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120500"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(MAX_NB_WORDS, len(word_index))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i run my own w2v instead\n",
    "embedding_matrix=vecs\n",
    "nb_words=400000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n########################################\\n## prepare embeddings - skip that, I use my own w2v\\n########################################\\nprint('Preparing embedding matrix')\\n\\nnb_words = min(MAX_NB_WORDS, len(word_index))+1\\n\\nembedding_matrix = np.zeros((nb_words, EMBEDDING_DIM))\\nfor word, i in word_index.items():\\n    if word in word2vec.vocab:\\n        embedding_matrix[i] = word2vec.word_vec(word)\\nprint('Null word embeddings: %d' % np.sum(np.sum(embedding_matrix, axis=1) == 0))\\n\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "########################################\n",
    "## prepare embeddings - skip that, I use my own w2v\n",
    "########################################\n",
    "print('Preparing embedding matrix')\n",
    "\n",
    "nb_words = min(MAX_NB_WORDS, len(word_index))+1\n",
    "\n",
    "embedding_matrix = np.zeros((nb_words, EMBEDDING_DIM))\n",
    "for word, i in word_index.items():\n",
    "    if word in word2vec.vocab:\n",
    "        embedding_matrix[i] = word2vec.word_vec(word)\n",
    "print('Null word embeddings: %d' % np.sum(np.sum(embedding_matrix, axis=1) == 0))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "## sample train/validation data\n",
    "########################################\n",
    "#np.random.seed(1234)\n",
    "perm = np.random.permutation(len(data_1))\n",
    "idx_train = perm[:int(len(data_1)*(1-VALIDATION_SPLIT))]\n",
    "idx_val = perm[int(len(data_1)*(1-VALIDATION_SPLIT)):]\n",
    "\n",
    "data_1_train = np.vstack((data_1[idx_train], data_2[idx_train]))\n",
    "data_2_train = np.vstack((data_2[idx_train], data_1[idx_train])) #gidi: he puts q1-q2, and q2-q1 what doubles the data set///\n",
    "labels_train = np.concatenate((labels[idx_train], labels[idx_train]))\n",
    "\n",
    "data_1_val = np.vstack((data_1[idx_val], data_2[idx_val]))\n",
    "data_2_val = np.vstack((data_2[idx_val], data_1[idx_val]))\n",
    "labels_val = np.concatenate((labels[idx_val], labels[idx_val]))\n",
    "\n",
    "weight_val = np.ones(len(labels_val))\n",
    "if re_weight:\n",
    "    weight_val *= 0.472001959\n",
    "    weight_val[labels_val==0] = 1.309028344"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,    0,    0,    0,    2,    3,    1, 1254,   61, 1254,\n",
       "       2921,    8,  578,    7,  759,  370,    7,   35], dtype=int32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "## define the model structure\n",
    "########################################\n",
    "embedding_layer = Embedding(nb_words, EMBEDDING_DIM, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH,\n",
    "        trainable=False)\n",
    "\n",
    "lstm_layer = LSTM(num_lstm, dropout_W=rate_drop_lstm, dropout_U=rate_drop_lstm)\n",
    "\n",
    "sequence_1_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences_1 = embedding_layer(sequence_1_input)\n",
    "x1 = lstm_layer(embedded_sequences_1)\n",
    "\n",
    "sequence_2_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences_2 = embedding_layer(sequence_2_input)\n",
    "y1 = lstm_layer(embedded_sequences_2)\n",
    "\n",
    "merged = merge([x1, y1],mode='concat')\n",
    "merged = Dropout(rate_drop_dense)(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "\n",
    "merged = Dense(num_dense, activation=act)(merged)\n",
    "merged = Dropout(rate_drop_dense)(merged)\n",
    "merged = BatchNormalization()(merged)\n",
    "\n",
    "preds = Dense(1, activation='sigmoid')(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "## add class weight\n",
    "########################################\n",
    "if re_weight:\n",
    "    class_weight = {0: 1.309028344, 1: 0.472001959}\n",
    "else:\n",
    "    class_weight = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, ..., 0, 0, 0])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "########################################\n",
    "## train the model\n",
    "########################################\n",
    "results_path='/mnt/quora_kaggle/results/'\n",
    "\n",
    "model = Model([sequence_1_input, sequence_2_input],preds)\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='nadam',metrics=['acc'])\n",
    "\n",
    "#model.summary()\n",
    "print(STAMP)\n",
    "\n",
    "early_stopping =EarlyStopping(monitor='val_loss', patience=3)\n",
    "bst_model_path = results_path+STAMP + '.h5'\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(bst_model_path, save_best_only=True, save_weights_only=True)\n",
    "\n",
    "hist = model.fit([data_1_train, data_2_train], labels_train, \\\n",
    "        validation_data=([data_1_val, data_2_val], labels_val, weight_val), \\\n",
    "        nb_epoch=200, batch_size=2048, shuffle=True, \\\n",
    "        class_weight=class_weight, callbacks=[early_stopping, model_checkpoint])\n",
    "\n",
    "model.load_weights(bst_model_path)\n",
    "bst_val_score = min(hist.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start making the submission before fine-tuning\n",
      " 155648/2345796 [>.............................] - ETA: 168s"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-a9d6a2ad11bc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Start making the submission before fine-tuning'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_data_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data_2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8192\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtest_data_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data_1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8192\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m   1270\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m         return self._predict_loop(f, ins,\n\u001b[0;32m-> 1272\u001b[0;31m                                   batch_size=batch_size, verbose=verbose)\n\u001b[0m\u001b[1;32m   1273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m     def train_on_batch(self, x, y,\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_predict_loop\u001b[0;34m(self, f, ins, batch_size, verbose)\u001b[0m\n\u001b[1;32m    943\u001b[0m                 \u001b[0mins_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 945\u001b[0;31m             \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m                 \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1941\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1942\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 1943\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   1944\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "########################################\n",
    "## make the submission\n",
    "########################################\n",
    "print('Start making the submission before fine-tuning')\n",
    "\n",
    "preds = model.predict([test_data_1, test_data_2], batch_size=8192, verbose=1)\n",
    "preds += model.predict([test_data_2, test_data_1], batch_size=8192, verbose=1)\n",
    "preds /= 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#new_preds_1 = do_clip(sub_preds,0.82)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({'test_id':test_ids, 'is_duplicate':np.clip(preds, 0.03, 0.97).ravel()})\n",
    "submission.to_csv('%.4f_'%(results_path+bst_val_score)+STAMP+'.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## abishak LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers.recurrent import LSTM, GRU\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.engine.topology import Merge\n",
    "from keras.layers import TimeDistributed, Lambda\n",
    "from keras.layers import Convolution1D, GlobalMaxPooling1D\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.layers.advanced_activations import PReLU\n",
    "from keras.preprocessing import sequence, text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_csv('data/quora_duplicate_questions.tsv', sep='\\t')\n",
    "y = labels#data.is_duplicate.values\n",
    "\n",
    "tk = text.Tokenizer(nb_words=200000)\n",
    "\n",
    "max_len = 40\n",
    "tk.fit_on_texts(list(data.question1.values) + list(data.question2.values.astype(str)))\n",
    "x1 = tk.texts_to_sequences(data.question1.values)\n",
    "x1 = sequence.pad_sequences(x1, maxlen=max_len)\n",
    "\n",
    "x2 = tk.texts_to_sequences(data.question2.values.astype(str))\n",
    "x2 = sequence.pad_sequences(x2, maxlen=max_len)\n",
    "\n",
    "word_index = tk.word_index\n",
    "\n",
    "ytrain_enc = np_utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "embeddings_index = {}\n",
    "f = open('data/glove.840B.300d.txt')\n",
    "for line in tqdm(f):\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "embedding_matrix = np.zeros((len(word_index) + 1, 300))\n",
    "for word, i in tqdm(word_index.items()):\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "'''\n",
    "max_features = 200000\n",
    "filter_length = 5\n",
    "nb_filter = 64\n",
    "pool_length = 4\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#using my stuff here\n",
    "def create_emb():\n",
    "    n_fact = vecs.shape[1]\n",
    "    emb = np.zeros((vocab_size, n_fact))\n",
    "\n",
    "    for i in range(1,len(emb)):\n",
    "        word = idx2word[i]\n",
    "        if word and re.match(r\"^[a-zA-Z0-9\\-]*$\", word):\n",
    "            try:\n",
    "                src_idx = wordidx[word]\n",
    "                emb[i] = vecs[src_idx]\n",
    "            except:\n",
    "                emb[i] = normal(scale=0.6, size=(n_fact,))\n",
    "        else:\n",
    "            # If we can't find the word in glove, randomly initialize\n",
    "            emb[i] = normal(scale=0.6, size=(n_fact,))\n",
    "\n",
    "    # This is our \"rare word\" id - we want to randomly initialize\n",
    "    emb[-1] = normal(scale=0.6, size=(n_fact,))\n",
    "    emb/=3\n",
    "    return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'biennials': 130852,\n",
       " 'verplank': 42458,\n",
       " 'soestdijk': 274735,\n",
       " 'woode': 311324,\n",
       " 'mdbo': 212156,\n",
       " 'sowell': 65544,\n",
       " 'mdbu': 119490,\n",
       " 'woods': 2507,\n",
       " 'spiders': 19780,\n",
       " 'mdbs': 285106,\n",
       " 'mdbr': 131910,\n",
       " 'woody': 10967,\n",
       " 'trawling': 56782,\n",
       " 'hwasung': 389348,\n",
       " 'spidery': 126257,\n",
       " 'regularize': 106404,\n",
       " 'hennings': 85340,\n",
       " 'canes': 34403,\n",
       " 'canet': 110349,\n",
       " 'caney': 97434,\n",
       " 'yusaf': 223713,\n",
       " 'chanthaburi': 154208,\n",
       " 'igual': 120122,\n",
       " 'comptuex': 399730,\n",
       " 'caned': 78728,\n",
       " 'mirisch': 180868,\n",
       " 'kalecik': 246349,\n",
       " 'rickman': 54345,\n",
       " 'jacquemod': 117004,\n",
       " 'ioannidis': 142172,\n",
       " 'canel': 299678,\n",
       " 'canem': 357071,\n",
       " 'afikoman': 354205,\n",
       " 'draÅ¾a': 228083,\n",
       " 'heliothis': 265609,\n",
       " 'replacer': 292996,\n",
       " 'pigment': 29943,\n",
       " 'bogyman': 343214,\n",
       " 'transvestism': 191391,\n",
       " 'fuste': 333859,\n",
       " 'Ä\\x91Æ°á»\\x9dng': 265245,\n",
       " 'seamier': 168003,\n",
       " 'illtyd': 307371,\n",
       " 'wooded': 17054,\n",
       " 'shipworms': 359396,\n",
       " 'boorstein': 310641,\n",
       " 'grueling': 17482,\n",
       " 'persita': 353293,\n",
       " 'wooden': 4836,\n",
       " 'iÌ\\x87kinci': 266703,\n",
       " 'virtuosos': 106586,\n",
       " 'altagracia': 143564,\n",
       " 'salination': 281659,\n",
       " 'wasescha': 358972,\n",
       " 'troutwine': 317961,\n",
       " 'gentzen': 277293,\n",
       " 'immunities': 62734,\n",
       " 'all-news': 112065,\n",
       " 'two-and-a-half-story': 313321,\n",
       " 'thrace': 37329,\n",
       " 'maytham': 203124,\n",
       " 'gaskets': 105598,\n",
       " 'snuggles': 206430,\n",
       " 'abdulwahab': 122684,\n",
       " '2.1-million': 192796,\n",
       " 'deadheads': 97059,\n",
       " 'pulavar': 297085,\n",
       " '266-megahertz': 343224,\n",
       " 'consenting': 51514,\n",
       " 'snuggled': 96539,\n",
       " 'guntermann': 353430,\n",
       " 'grandcourt': 375388,\n",
       " 'usenet': 37999,\n",
       " 'videodrome': 242494,\n",
       " 'outfielders': 36723,\n",
       " 'niepoÅ\\x82omice': 310787,\n",
       " 'isbin': 241976,\n",
       " '68-94': 389284,\n",
       " 'phealy': 242304,\n",
       " 'somjit': 128408,\n",
       " 'trivikram': 337925,\n",
       " 'rocque': 125626,\n",
       " 'bhubaneshwar': 115706,\n",
       " 'caner': 164625,\n",
       " 'quagmires': 146686,\n",
       " 'ulpia': 217294,\n",
       " 'macarounas': 361946,\n",
       " 'scharffenberger': 240240,\n",
       " 'burlapped': 342613,\n",
       " 'pericardial': 134421,\n",
       " 'convy': 215964,\n",
       " '1670s': 100472,\n",
       " 'yugoslavians': 184376,\n",
       " 'uplifting': 28687,\n",
       " 'collyns': 350146,\n",
       " 'bakikhanov': 386006,\n",
       " 'deferring': 40678,\n",
       " 'gayathri': 168340,\n",
       " 'talbi': 249360,\n",
       " 'tootling': 300899,\n",
       " 'gastein': 93296,\n",
       " 'topography': 23638,\n",
       " 'gainsbourg': 64587,\n",
       " 'sebokeng': 306026,\n",
       " 'evzen': 355370,\n",
       " 'birrell': 110824,\n",
       " 'mclaurin': 115449,\n",
       " 'airball': 110983,\n",
       " 'unsinkable': 80028,\n",
       " 'hiranuma': 99649,\n",
       " 'long-period': 174330,\n",
       " '60-hour': 90832,\n",
       " 'dne': 285575,\n",
       " 'dnd': 119002,\n",
       " 'agassi': 7320,\n",
       " 'dnf': 45844,\n",
       " 'dna': 4319,\n",
       " 'dnc': 19588,\n",
       " 'dnb': 73032,\n",
       " 'dnm': 335416,\n",
       " 'dnl': 190074,\n",
       " 'dno': 123877,\n",
       " 'dni': 71583,\n",
       " 'agasse': 352553,\n",
       " 'sidebars': 67480,\n",
       " 'dnt': 109559,\n",
       " 'dnv': 170378,\n",
       " 'dnq': 221804,\n",
       " 'dnp': 56597,\n",
       " 'dns': 36758,\n",
       " 'dnr': 72431,\n",
       " 'spaying': 143032,\n",
       " 'benedikt': 95596,\n",
       " 'riddoch': 286729,\n",
       " 'borstal': 134316,\n",
       " 'duckwitz': 361002,\n",
       " 'populations': 6022,\n",
       " 'mesmerize': 147718,\n",
       " 'nakaya': 273525,\n",
       " 'quinnell': 101857,\n",
       " 'yahoo': 6600,\n",
       " 'meteorologist': 22154,\n",
       " 'expeditionary': 16795,\n",
       " 'polÃ\\xadcia': 213812,\n",
       " 'echelon': 30883,\n",
       " 'gija': 241797,\n",
       " 'shovelful': 231719,\n",
       " 'equilateral': 87157,\n",
       " 'canek': 245368,\n",
       " 'barberis': 166282,\n",
       " 'jumbling': 274108,\n",
       " 'nickson': 123531,\n",
       " '(406)': 199194,\n",
       " 'fahlgren': 380045,\n",
       " 'pluess': 229326,\n",
       " 'ozment': 351079,\n",
       " 'dangdut': 163548,\n",
       " 'expressively': 150601,\n",
       " 'subgenus': 44533,\n",
       " 'fluorite': 116228,\n",
       " 'jidaigeki': 195450,\n",
       " 'disparagement': 104971,\n",
       " 'insectarium': 239856,\n",
       " 'sunrays': 296114,\n",
       " 'azurite': 205144,\n",
       " 'irrationalism': 296082,\n",
       " 'kraig': 150591,\n",
       " '18m': 166156,\n",
       " 'sleptsova': 185104,\n",
       " 'hayaniyah': 247333,\n",
       " 'shirked': 110947,\n",
       " 'constantinopolitan': 268749,\n",
       " 'voyevodin': 364594,\n",
       " 'berlijn': 221301,\n",
       " 'krait': 159305,\n",
       " 'defillippo': 203104,\n",
       " 'keweenaw': 109342,\n",
       " 'fukunaga': 108359,\n",
       " '501,000': 274950,\n",
       " 'baladi': 177158,\n",
       " 'barbra': 29154,\n",
       " 'flossie': 102809,\n",
       " '343,000': 156517,\n",
       " 'assimilated': 31202,\n",
       " 'shorin': 356745,\n",
       " 'barbro': 178853,\n",
       " 'dinosaurs': 14727,\n",
       " 'fimbriata': 173458,\n",
       " 'varyingly': 354357,\n",
       " 'criterion-referenced': 336768,\n",
       " 'ouroboros': 183444,\n",
       " 'assimilates': 174001,\n",
       " 'hohenwart': 336687,\n",
       " 'chandor': 265390,\n",
       " 'chandos': 73869,\n",
       " '40-foot': 36888,\n",
       " 'bollnÃ¤s': 293178,\n",
       " 'knapik': 317121,\n",
       " 'miyavi': 376228,\n",
       " 'olhovskiy': 94573,\n",
       " 'chandon': 86559,\n",
       " 'ligustrum': 207321,\n",
       " 'disengaging': 110079,\n",
       " 'smashers': 197233,\n",
       " 'sprawling': 8943,\n",
       " 'goldfeld': 225736,\n",
       " 'welcomed': 3735,\n",
       " 'toukan': 206220,\n",
       " 'malba': 290337,\n",
       " 'stoicism': 63915,\n",
       " 'tÃ©llez-girÃ³n': 270207,\n",
       " 'tillamook': 84985,\n",
       " 'virage': 223131,\n",
       " 'mutahi': 245162,\n",
       " 'claflin': 91724,\n",
       " 'activating': 33975,\n",
       " 'takeshita': 96266,\n",
       " 'welcomes': 9791,\n",
       " 'fir': 24294,\n",
       " 'fis': 18427,\n",
       " 'fip': 106329,\n",
       " 'fiq': 203147,\n",
       " 'fiv': 211659,\n",
       " 'fiw': 258304,\n",
       " 'fit': 3130,\n",
       " 'fiu': 66543,\n",
       " 'fiz': 90093,\n",
       " 'screaming': 9225,\n",
       " 'fix': 5054,\n",
       " 'lapuz': 368814,\n",
       " 'deniyev': 227776,\n",
       " 'folate': 70255,\n",
       " 'fib': 93561,\n",
       " 'fic': 129227,\n",
       " 'fia': 15155,\n",
       " 'fif': 165740,\n",
       " 'fig': 23573,\n",
       " 'fid': 137325,\n",
       " 'fie': 101892,\n",
       " 'fij': 95376,\n",
       " 'fuddruckers': 204089,\n",
       " 'fih': 76314,\n",
       " 'fii': 188606,\n",
       " 'fin': 11721,\n",
       " 'fio': 192519,\n",
       " 'fil': 32059,\n",
       " 'fim': 62213,\n",
       " 'tcby': 321727,\n",
       " 'foolin': 228793,\n",
       " 'beilhart': 380285,\n",
       " 'shivas': 372074,\n",
       " 'marabouts': 167911,\n",
       " 'shivam': 194444,\n",
       " 'shivan': 260741,\n",
       " '18w': 341553,\n",
       " 'sova': 112200,\n",
       " 'matamoras': 270755,\n",
       " 'jugendstil': 145954,\n",
       " 'classe': 105149,\n",
       " 'hospitalier': 219525,\n",
       " 'scaglione': 201759,\n",
       " 'orlicÃ\\xad': 173661,\n",
       " 'sub-antarctic': 208207,\n",
       " 'dimidiatus': 330262,\n",
       " 'elizardo': 99284,\n",
       " 'ii-era': 112023,\n",
       " 'frewen': 243836,\n",
       " 'sugarplums': 279988,\n",
       " 'frewer': 201646,\n",
       " 'heathfield': 88528,\n",
       " 'diatchenko': 196983,\n",
       " 'waialae': 121440,\n",
       " 'calliotropidae': 226154,\n",
       " 'verkehrsverbund': 136769,\n",
       " 'labbadia': 159260,\n",
       " 'kowt': 149638,\n",
       " 'zuid': 149014,\n",
       " 'gaucelm': 381735,\n",
       " 'pavlina': 161556,\n",
       " 'parasites': 23615,\n",
       " 'mandlÃ\\xadkovÃ¡': 274151,\n",
       " 'kowa': 193592,\n",
       " 'pisos': 388399,\n",
       " '3,770': 187654,\n",
       " '3,771': 345979,\n",
       " '3,772': 261748,\n",
       " 'jokanovic': 131512,\n",
       " '3,775': 219012,\n",
       " '3,776': 320769,\n",
       " 'syf': 76199,\n",
       " 'sandstrÃ¶m': 190369,\n",
       " 'ideograph': 394653,\n",
       " 'mannerheim': 92831,\n",
       " 'multi-point': 189505,\n",
       " 'wildeboer': 267692,\n",
       " 'lapua': 128499,\n",
       " 'beaning': 153223,\n",
       " 'malczewski': 338761,\n",
       " 'combinatorial': 54041,\n",
       " '39,400': 378011,\n",
       " 'unarmored': 116710,\n",
       " '1950-53': 22773,\n",
       " 'nastya': 212551,\n",
       " '1950-51': 109106,\n",
       " 'mcauslan': 260730,\n",
       " 'abbott': 11748,\n",
       " 'ronsard': 174108,\n",
       " 'abbots': 52508,\n",
       " 'aduritz': 314171,\n",
       " 'beristain': 231852,\n",
       " 'bonelli': 102380,\n",
       " 'pumpkins': 29571,\n",
       " 'bonello': 195564,\n",
       " 'stamler': 180968,\n",
       " 'kejian': 227507,\n",
       " 'berwick': 32710,\n",
       " 'syl': 122625,\n",
       " 'sikiru': 362769,\n",
       " 'guenette': 375379,\n",
       " 'parkson': 177176,\n",
       " 'eavesdroppers': 132140,\n",
       " 'torrico': 188191,\n",
       " 'townlands': 77185,\n",
       " 'rosbank': 307401,\n",
       " 'portmanteau': 50745,\n",
       " 'ineffectively': 121965,\n",
       " 'go-on': 365873,\n",
       " '95-minute': 206690,\n",
       " 'polygala': 274273,\n",
       " 'lazers': 244716,\n",
       " 'curiouser': 168047,\n",
       " 'stoneham': 60804,\n",
       " 'skanderbeg': 57151,\n",
       " 'hushang': 355269,\n",
       " 'tumer': 192765,\n",
       " 'chudes': 375068,\n",
       " 'stylistics': 125573,\n",
       " '20sec': 186896,\n",
       " 'multi-city': 304621,\n",
       " 'allectus': 368185,\n",
       " 'witzenhausen': 351773,\n",
       " 'aigles': 277966,\n",
       " 'casamance': 54911,\n",
       " 'listened-to': 299375,\n",
       " 'yuraszeck': 176601,\n",
       " 'grossness': 225599,\n",
       " 'fugett': 395057,\n",
       " 'palank': 393610,\n",
       " 'redfearn': 182389,\n",
       " 'ragione': 369710,\n",
       " 'fuzziness': 145086,\n",
       " '1937-1939': 263965,\n",
       " 'casandra': 206113,\n",
       " 'sepecat': 292673,\n",
       " 'pulsations': 149534,\n",
       " 'recber': 74081,\n",
       " 'tri-rail': 188659,\n",
       " 'achaemenian': 331277,\n",
       " 'end-of-war': 144995,\n",
       " 'three-bay': 93418,\n",
       " 'farinos': 260945,\n",
       " 'homestore': 115032,\n",
       " 'winterville': 238677,\n",
       " 'heftiest': 217252,\n",
       " 'positively': 10285,\n",
       " '.680': 279370,\n",
       " 'ahmed': 3212,\n",
       " 'rouille': 331556,\n",
       " 'masroor': 142914,\n",
       " 'warnke': 126282,\n",
       " '.681': 318860,\n",
       " 'ahmen': 350611,\n",
       " '.682': 181364,\n",
       " 'tomkiewicz': 367323,\n",
       " 'veillet': 305590,\n",
       " 'ahmet': 25345,\n",
       " 'exclaimed': 28163,\n",
       " 'schuur': 131041,\n",
       " 'friend': 1409,\n",
       " 'english-subtitled': 371872,\n",
       " 'vasiljkovic': 151521,\n",
       " '.684': 165658,\n",
       " 'lingga': 187200,\n",
       " 'legibus': 345961,\n",
       " 'wandrei': 279869,\n",
       " 'squatty': 347152,\n",
       " '.687': 192274,\n",
       " 'eslami': 121163,\n",
       " '2.7-mile': 261692,\n",
       " '.688': 179499,\n",
       " 'wandrey': 379082,\n",
       " 'iseco': 342894,\n",
       " 'stohl': 76539,\n",
       " 'marwaheen': 236484,\n",
       " 'maj.': 7117,\n",
       " 'microprinting': 346622,\n",
       " 'mickle': 126720,\n",
       " 'koose': 367162,\n",
       " '45th': 19024,\n",
       " 'karsavina': 323057,\n",
       " 'tiep': 376188,\n",
       " 'yushun': 334605,\n",
       " '1570s': 124494,\n",
       " 'tu-22m': 281444,\n",
       " '4,052': 394833,\n",
       " 'huhtala': 242761,\n",
       " 'teesdale': 151172,\n",
       " 'reverence': 26886,\n",
       " 'koosh': 364397,\n",
       " '9,500-strong': 189331,\n",
       " 'rocketplane': 201765,\n",
       " 'majo': 229549,\n",
       " 'maji': 140749,\n",
       " 'majd': 115428,\n",
       " 'maja': 50645,\n",
       " 'nettle': 72968,\n",
       " 'ankylosaurs': 299887,\n",
       " 'ecclesiasticus': 217883,\n",
       " 'fugitives': 15100,\n",
       " 'hiatt': 55691,\n",
       " 'maju': 127731,\n",
       " 'navias': 164365,\n",
       " 'morawetz': 335464,\n",
       " 'shakaki': 71095,\n",
       " 'dickey': 26618,\n",
       " 'katsuji': 252177,\n",
       " 'x-play': 152725,\n",
       " '156.4': 241885,\n",
       " 'dicker': 62585,\n",
       " 'gillham': 185373,\n",
       " 'dicken': 191895,\n",
       " 'dickel': 169950,\n",
       " 'otello': 64301,\n",
       " 'apace': 57468,\n",
       " 'wunderman': 188306,\n",
       " '1,000-person': 265733,\n",
       " 'non-defense': 390635,\n",
       " 'warmongering': 85542,\n",
       " 'kaiapoi': 177267,\n",
       " 'wonersh': 312434,\n",
       " 'lepidoptera': 51966,\n",
       " 'xlvii': 138789,\n",
       " 'bruneian': 151567,\n",
       " 'hoeing': 216422,\n",
       " 'theodosios': 329158,\n",
       " 'afala': 183743,\n",
       " 'uncleanliness': 318322,\n",
       " 'rÃ©mi': 157066,\n",
       " 'blackfaced': 352819,\n",
       " 'supercoppa': 147341,\n",
       " 'polytrack': 164589,\n",
       " 'ennedi': 261119,\n",
       " 'cross-breeding': 215629,\n",
       " 'navasota': 135251,\n",
       " 'rÃ©my': 114746,\n",
       " 'mriya': 397892,\n",
       " 'dowlatabadi': 167653,\n",
       " 'kharja': 200272,\n",
       " 'multi-starrer': 310380,\n",
       " 'primorac': 94143,\n",
       " 'conant': 60567,\n",
       " 'programmatic': 62023,\n",
       " 'presstek': 121600,\n",
       " 'garamendi': 57757,\n",
       " 'homestore.com': 170474,\n",
       " 'turkish-cypriot': 297771,\n",
       " 'zahler': 205393,\n",
       " 'tyndale': 59489,\n",
       " 'doral': 40970,\n",
       " 'mmorris': 331139,\n",
       " 'tyndall': 53965,\n",
       " 'bifengxia': 311609,\n",
       " 'doran': 39172,\n",
       " 'firnas': 281413,\n",
       " 'devellano': 231746,\n",
       " 'motional': 301034,\n",
       " 'itzler': 295639,\n",
       " 'wanyoike': 298966,\n",
       " 'guided-missile': 111747,\n",
       " 'nongkai': 226778,\n",
       " 'conductive': 46557,\n",
       " 'sunbeams': 197609,\n",
       " 'spectrometers': 93234,\n",
       " '49,999': 360431,\n",
       " 'helipads': 172864,\n",
       " 'sletten': 291513,\n",
       " 'aftereffect': 224271,\n",
       " 'lapping': 52661,\n",
       " 'meraclis': 326762,\n",
       " 'meridional': 148061,\n",
       " 'tendons': 40874,\n",
       " 'waga': 123008,\n",
       " 'on-premise': 204181,\n",
       " '29th': 13586,\n",
       " 'westrail': 352122,\n",
       " 'coniine': 397793,\n",
       " 'qtrax': 232812,\n",
       " 'almos': 395260,\n",
       " 'semi-state': 247474,\n",
       " 'karibi': 282640,\n",
       " 'ciardullo': 197033,\n",
       " 'khandaq': 373163,\n",
       " 'narcoterrorists': 329114,\n",
       " 'corvair': 106421,\n",
       " '4.3': 10290,\n",
       " 'a-group': 354019,\n",
       " '65.72': 310024,\n",
       " 'zigged': 248234,\n",
       " 'ofsted': 47251,\n",
       " 'bloggers': 19305,\n",
       " 'meaningfulness': 207688,\n",
       " 'felicidad': 178660,\n",
       " 'month-long': 66905,\n",
       " 'escalade': 53543,\n",
       " 'costa-gavras': 277181,\n",
       " 'otolaryngologists': 359851,\n",
       " 'escalada': 203010,\n",
       " 'dinoponera': 335963,\n",
       " '(863)': 331001,\n",
       " 'lanett': 375610,\n",
       " 'microcap': 183690,\n",
       " 'finsbury': 56234,\n",
       " 'communicants': 150817,\n",
       " 'gamelyn': 371386,\n",
       " 'unstick': 231256,\n",
       " 'giessen': 81789,\n",
       " 'obese': 18864,\n",
       " 'sensationalized': 95228,\n",
       " 'arkie': 382531,\n",
       " 'arkia': 129441,\n",
       " 'arkin': 44256,\n",
       " 'wagr': 134932,\n",
       " 'lisha': 302154,\n",
       " 'fibroblast': 118483,\n",
       " 'satrapies': 232855,\n",
       " 'jarrin': 159446,\n",
       " 'alcocer': 142059,\n",
       " 'abdo': 86743,\n",
       " 'faktor': 372710,\n",
       " 'propellants': 68400,\n",
       " 'tupinambÃ¡': 398311,\n",
       " 'bogacheva': 335683,\n",
       " '1670': 37934,\n",
       " 'mazher': 305561,\n",
       " 'sreten': 130933,\n",
       " 'misconstrued': 58480,\n",
       " 'khorchin': 334075,\n",
       " 'forwarder': 161322,\n",
       " 'freinsheim': 372131,\n",
       " 'port-louis': 257753,\n",
       " 'blowpipes': 397864,\n",
       " 'majid': 17579,\n",
       " 'unos': 61933,\n",
       " 'majic': 176173,\n",
       " 'canoeing': 27275,\n",
       " 'majia': 335418,\n",
       " 'majin': 162650,\n",
       " 'gumhuriya': 286011,\n",
       " 'majik': 264904,\n",
       " 'embargos': 183285,\n",
       " 'sub-leased': 385804,\n",
       " 'bundelkhand': 115538,\n",
       " 'waddell': 34315,\n",
       " 'unog': 311654,\n",
       " 'hyperdrive': 142691,\n",
       " 'kayama': 218566,\n",
       " 'chunlai': 98615,\n",
       " 'bricklayer': 62273,\n",
       " 'twinkles': 198567,\n",
       " 'remand': 41416,\n",
       " 'ivillage.com': 253928,\n",
       " 'world-herald': 224949,\n",
       " 'pahlavas': 233858,\n",
       " 'spews': 71826,\n",
       " '177.2': 274826,\n",
       " 'viticulturist': 276331,\n",
       " 'remans': 198903,\n",
       " 'zeon': 141591,\n",
       " 'keratsini': 381367,\n",
       " 'baudry': 172032,\n",
       " 'viertel': 123180,\n",
       " 'sitompul': 263400,\n",
       " 'georgics': 210353,\n",
       " 'braÅ\\x9fov': 87871,\n",
       " '76-74': 142987,\n",
       " '76-75': 142572,\n",
       " '76-76': 280959,\n",
       " '76-77': 321686,\n",
       " '76-70': 238224,\n",
       " '76-71': 211426,\n",
       " '76-72': 199176,\n",
       " '76-73': 165956,\n",
       " 'three-hole': 371740,\n",
       " 'nkumbula': 297897,\n",
       " 'cost-effectiveness': 122186,\n",
       " 'zeos': 293651,\n",
       " 'pacey': 97259,\n",
       " 'peremptory': 85244,\n",
       " 'denaturing': 226219,\n",
       " 'tamkang': 104958,\n",
       " 'mentors': 25785,\n",
       " 'mentorn': 396147,\n",
       " 'field-based': 266297,\n",
       " 'stillness': 53566,\n",
       " 'cineastes': 187694,\n",
       " 'water-skiing': 218070,\n",
       " 'willesden': 88126,\n",
       " 'absurdities': 67871,\n",
       " 'hillsgrove': 325843,\n",
       " 'dawnay': 185023,\n",
       " 'paramatman': 378169,\n",
       " 'waterboard': 231271,\n",
       " 'preorbital': 344878,\n",
       " 'adenhart': 131871,\n",
       " 'olabisi': 292027,\n",
       " 'senecas': 148799,\n",
       " 'upsides': 152457,\n",
       " 'phosphotransferases': 229092,\n",
       " 'marignane': 139733,\n",
       " 'braye': 255426,\n",
       " 'radzinsky': 214411,\n",
       " 'marignano': 274190,\n",
       " 'keynesians': 187461,\n",
       " 'oneya': 393612,\n",
       " 'gasteig': 362726,\n",
       " 'brays': 196116,\n",
       " 'ruleta': 379678,\n",
       " 'radzinski': 100109,\n",
       " 'u.n.-assisted': 150234,\n",
       " 'bhatkhande': 291810,\n",
       " 'dokka': 210603,\n",
       " 'yukawa': 144648,\n",
       " 'moleskine': 296322,\n",
       " 'chayim': 263698,\n",
       " 'phengaris': 360133,\n",
       " 'objective': 5241,\n",
       " 'indicative': 19631,\n",
       " 'veliyev': 380103,\n",
       " 'stallings': 57080,\n",
       " 'riskiness': 142847,\n",
       " 'nonconsecutive': 147881,\n",
       " 'sleuthing': 74879,\n",
       " 'semi': 3922,\n",
       " 'rogstad': 264445,\n",
       " 'rifting': 111726,\n",
       " 'b.c.e.': 138377,\n",
       " 'multi-sensory': 273533,\n",
       " 'uchinoura': 350008,\n",
       " '50-piece': 346899,\n",
       " 'walk-on': 87982,\n",
       " 'budejovice': 134061,\n",
       " 'ojanen': 272312,\n",
       " '25-49': 326049,\n",
       " 'm1903': 225562,\n",
       " '25-45': 332741,\n",
       " '25-44': 236125,\n",
       " '25-40': 132841,\n",
       " 'trachelipus': 390288,\n",
       " 'pileggi': 89815,\n",
       " 'lockdown': 34484,\n",
       " 'gambale': 181252,\n",
       " 'khoshchehreh': 345517,\n",
       " 'fruj': 282828,\n",
       " 'fruh': 320061,\n",
       " 'kubÅ\\x8d': 354747,\n",
       " 'frum': 80040,\n",
       " 'frua': 246620,\n",
       " 'ilderton': 382647,\n",
       " 'frug': 236219,\n",
       " 'pipestone': 128838,\n",
       " 'frue': 292533,\n",
       " 'frud': 231348,\n",
       " 'lswr': 69348,\n",
       " 'shwebo': 205404,\n",
       " 'taifas': 279896,\n",
       " 'dng': 176790,\n",
       " 'mackle': 240907,\n",
       " 'sharqi': 44613,\n",
       " 'herrin': 95853,\n",
       " 'http://www.loc.gov': 335648,\n",
       " 'venpres': 160841,\n",
       " 'kymmene': 72668,\n",
       " 'herria': 236606,\n",
       " 'spaceships': 53665,\n",
       " 'two-channel': 225558,\n",
       " 'mccumber': 82773,\n",
       " 'anomalous': 46845,\n",
       " 'pfaffenbach': 311875,\n",
       " 'officeholders': 49598,\n",
       " 'kellett': 82007,\n",
       " 'nerkin': 310093,\n",
       " 'vonage': 54559,\n",
       " 'ribozymes': 236637,\n",
       " 'agassa': 229435,\n",
       " 'duccio': 145554,\n",
       " 'pre-tax': 134422,\n",
       " 'bujsaim': 201429,\n",
       " 'marshall': 4695,\n",
       " 'honeymoon': 17999,\n",
       " 'nongovernmental': 28867,\n",
       " 'cekcyn': 295670,\n",
       " 'gasholder': 349984,\n",
       " 'marshals': 17446,\n",
       " 'haboush': 276353,\n",
       " 'pellatt': 296580,\n",
       " 'kleinbaum': 234949,\n",
       " 'biddulph': 112422,\n",
       " 'isayev': 142447,\n",
       " 'alexandrian': 67009,\n",
       " 'sacyr': 116750,\n",
       " 'jÃ¶nkÃ¶pings': 319152,\n",
       " 'tattershall': 262830,\n",
       " 'buttoning': 171891,\n",
       " 'cassiobury': 301200,\n",
       " '60,900': 321411,\n",
       " 'facchinetti': 180427,\n",
       " 'thesaurus': 64856,\n",
       " 'friederich': 126123,\n",
       " 'kaizers': 287869,\n",
       " 'bridgework': 292910,\n",
       " 'aktuna': 217798,\n",
       " 'endocytic': 343535,\n",
       " 'layia': 381878,\n",
       " 'horodecki': 329697,\n",
       " '63sm': 299139,\n",
       " 'layin': 157742,\n",
       " 'izakaya': 233099,\n",
       " 'non-discrimination': 116499,\n",
       " '2231': 377766,\n",
       " '733,000': 191183,\n",
       " 'open-air': 36751,\n",
       " 'mzilikazi': 181619,\n",
       " 'sovietskaya': 312384,\n",
       " 'liukko': 367716,\n",
       " 'dharmaguptaka': 225517,\n",
       " 'yasiri': 343204,\n",
       " 'sidanko': 144783,\n",
       " 'denzongpa': 241111,\n",
       " 'lemacon': 228681,\n",
       " 'rechecking': 210714,\n",
       " 'bedsheet': 119476,\n",
       " 'kobasew': 121443,\n",
       " 'oganesian': 390139,\n",
       " 'scuttled': 26264,\n",
       " 'fireboxes': 168588,\n",
       " '1995-99': 166994,\n",
       " '1995-98': 149370,\n",
       " 'hattrick': 84049,\n",
       " '1995-97': 114605,\n",
       " '1995-96': 25239,\n",
       " 'cambodia': 4113,\n",
       " 'encontrado': 328511,\n",
       " '11-percent': 134713,\n",
       " 'facelifted': 108144,\n",
       " 'sandaled': 341882,\n",
       " 'serous': 123320,\n",
       " 'obliges': 44444,\n",
       " 'carbonaceous': 108003,\n",
       " 'crowne': 63349,\n",
       " '.722': 128059,\n",
       " '.720': 210475,\n",
       " '.727': 102588,\n",
       " '.724': 285683,\n",
       " 'palmu': 369641,\n",
       " 'thoroughgoing': 119268,\n",
       " 'palms': 18279,\n",
       " 'suwon': 45925,\n",
       " 'buaya': 267645,\n",
       " 'palmy': 231807,\n",
       " 'gijs': 137012,\n",
       " 'palme': 26877,\n",
       " 'conservatively': 38618,\n",
       " 'moresby': 37794,\n",
       " 'yellowstone': 19935,\n",
       " 'kitson': 54930,\n",
       " 'palmo': 232360,\n",
       " 'palmi': 215194,\n",
       " 'cluck': 97382,\n",
       " 'reabsorption': 128610,\n",
       " 'innviertel': 388150,\n",
       " 'borle': 251137,\n",
       " 'hypoallergenic': 136504,\n",
       " 'coluim': 121765,\n",
       " 'fronsac': 227072,\n",
       " 'omran': 85033,\n",
       " 'larz': 191662,\n",
       " 'mattek-sands': 209177,\n",
       " 'finnyards': 269117,\n",
       " 'chail': 282385,\n",
       " 'chaim': 37978,\n",
       " 'chain': 2853,\n",
       " 'a.h.': 62595,\n",
       " 'chaib': 107387,\n",
       " 'egba': 190107,\n",
       " 'chaid': 311916,\n",
       " 'dustups': 337765,\n",
       " 'egbe': 238722,\n",
       " 'sherchan': 193260,\n",
       " 'hurtubise': 180965,\n",
       " 'zaiba': 383465,\n",
       " 'manjusri': 227223,\n",
       " 'chair': 3845,\n",
       " 'tampines': 98737,\n",
       " 'chait': 100606,\n",
       " 'macht': 69557,\n",
       " 'machu': 50033,\n",
       " 'ballet': 6508,\n",
       " 'grapples': 41559,\n",
       " 'grappler': 117923,\n",
       " 'airone': 378303,\n",
       " 'gyeon': 296819,\n",
       " 'cebuanos': 293434,\n",
       " 'mache': 67246,\n",
       " 'balled': 77790,\n",
       " 'grappled': 36584,\n",
       " 'pouha': 253981,\n",
       " 'macha': 66881,\n",
       " 'ballen': 74718,\n",
       " 'neuberger': 56691,\n",
       " 'macho': 22918,\n",
       " 'machi': 117783,\n",
       " 'estess': 358457,\n",
       " 'jero': 145180,\n",
       " 'jeri': 68841,\n",
       " 'flatbed': 44749,\n",
       " 'jerk': 16634,\n",
       " 'jere': 46627,\n",
       " 'jerd': 278193,\n",
       " 'lard': 46523,\n",
       " 'enflamed': 161925,\n",
       " 'optronics': 65649,\n",
       " 'elkridge': 194167,\n",
       " 'junhasavasdikul': 383492,\n",
       " 'stitchers': 313206,\n",
       " '1,391': 146601,\n",
       " 'bellemare': 106720,\n",
       " 'kalaallit': 327099,\n",
       " 'goodrem': 105931,\n",
       " 'exact': 5159,\n",
       " 'inglis': 38026,\n",
       " 'beightler': 381896,\n",
       " 'mach3': 148966,\n",
       " 'qanyare': 124465,\n",
       " 'larn': 285237,\n",
       " 'illustrators': 45161,\n",
       " 'castlebury': 164341,\n",
       " 'hodgins': 112242,\n",
       " 'steinlen': 336502,\n",
       " 'organon': 104075,\n",
       " 'cloppenburg': 178318,\n",
       " 'nestle-aland': 341447,\n",
       " 'larino': 305539,\n",
       " 'procacci': 352993,\n",
       " 'adorno': 74556,\n",
       " 'roundworm': 130920,\n",
       " 'tachov': 220122,\n",
       " 'biomechanist': 362774,\n",
       " 'trisha': 48364,\n",
       " 'svitavy': 148347,\n",
       " 'multicasting': 174807,\n",
       " 'adorns': 57315,\n",
       " 'castellum': 169543,\n",
       " 'afe': 154219,\n",
       " 'burca': 315643,\n",
       " '1.720': 385365,\n",
       " 'soebiandono': 260955,\n",
       " 'corazon': 35741,\n",
       " '1.725': 201333,\n",
       " 'burck': 189004,\n",
       " 'kongsak': 224609,\n",
       " 'antwerp': 15954,\n",
       " 'burch': 44430,\n",
       " 'tiete': 334820,\n",
       " '23-foot': 97825,\n",
       " 'matras': 315366,\n",
       " 'waguespack': 389052,\n",
       " 'ground': 817,\n",
       " 'hristo': 49411,\n",
       " 'koljevic': 72761,\n",
       " 'oldies': 26729,\n",
       " 'operacion': 160728,\n",
       " 'northey': 155025,\n",
       " 'yoyogi': 123551,\n",
       " 'hentemann': 292159,\n",
       " 'restiveness': 113719,\n",
       " 'uff': 117932,\n",
       " 'menjou': 176309,\n",
       " 'miiverse': 392014,\n",
       " 'chermiti': 210742,\n",
       " 'ponding': 274152,\n",
       " 'tretyakov': 77324,\n",
       " 'terazije': 193654,\n",
       " 'welkin': 271464,\n",
       " 'ramattan': 267192,\n",
       " 'sangakkara': 23863,\n",
       " 'coxswain': 71177,\n",
       " 'snowbirds': 83338,\n",
       " 'sertÃ£o': 235182,\n",
       " 'gurfinkel': 297176,\n",
       " 'stollmann': 276765,\n",
       " 'utdc': 371260,\n",
       " 'petroleo': 58612,\n",
       " 'sistemas': 149887,\n",
       " 'europÃ©enne': 127376,\n",
       " 'fakers': 174533,\n",
       " 'bigan': 201989,\n",
       " 'agesilaus': 172050,\n",
       " 'fichardt': 186423,\n",
       " 'fakery': 109645,\n",
       " 'lÃ©ger': 80739,\n",
       " 'iberians': 119912,\n",
       " 'handbags': 32907,\n",
       " 'pints': 44167,\n",
       " 'kamerman': 392987,\n",
       " 'akiga': 297239,\n",
       " 'liberalizing': 37953,\n",
       " 'hollygrove': 318704,\n",
       " 'halladay': 36003,\n",
       " 'zottoli': 276596,\n",
       " 'rehovot': 106213,\n",
       " 'ooooooo': 176204,\n",
       " 'oly-2004-gre': 143486,\n",
       " 'bharata': 83032,\n",
       " 'shyamala': 299956,\n",
       " 'bharati': 63127,\n",
       " 'cardinality': 80734,\n",
       " 'aquinnah': 172623,\n",
       " 'lutry': 384395,\n",
       " 'favorables': 386416,\n",
       " 'palazuelos': 255950,\n",
       " 'lutra': 201750,\n",
       " 'following': 284,\n",
       " 'fossen': 268809,\n",
       " 'fossel': 226780,\n",
       " 'corazÃ³n': 72108,\n",
       " 'selenium': 47811,\n",
       " 'stetson': 45080,\n",
       " 'greco-turkish': 111511,\n",
       " 'bar-ilan': 126395,\n",
       " 'brickowski': 141677,\n",
       " 'fossey': 97107,\n",
       " 'week-end': 161006,\n",
       " 'fosset': 283940,\n",
       " 'Ã±uÃ±oa': 391749,\n",
       " 'terance': 119729,\n",
       " 'eiichiro': 258683,\n",
       " 'ourso': 358185,\n",
       " 'sambawa': 290661,\n",
       " 'thanking': 23680,\n",
       " 'woreda': 37510,\n",
       " 'Ã©dition': 247714,\n",
       " 'powerbooks': 145615,\n",
       " 'avondre': 374073,\n",
       " 'proselytising': 173584,\n",
       " '13,000': 11605,\n",
       " 'compiegne': 162905,\n",
       " 'consolidator': 116084,\n",
       " 'twic.html': 239341,\n",
       " 'lucchetti': 292981,\n",
       " 'stapel': 265092,\n",
       " 'epidemiologic': 123167,\n",
       " 'well-produced': 295158,\n",
       " 'sociolinguistics': 141914,\n",
       " 'vulkan': 93720,\n",
       " 'stapes': 164378,\n",
       " 'insitute': 178983,\n",
       " 'harmon': 19667,\n",
       " 'yinan': 181373,\n",
       " 'jeremies': 88394,\n",
       " 'sandeep': 59374,\n",
       " '83.44': 385367,\n",
       " 'trialled': 80336,\n",
       " 'middle-income': 113189,\n",
       " 'skirmish': 21509,\n",
       " 'sliney': 221830,\n",
       " 'habte': 278655,\n",
       " 'f-4j': 387333,\n",
       " 'vlaicu': 202934,\n",
       " 'side-scan': 296158,\n",
       " 'deflagration': 251994,\n",
       " 'jungwirth': 185057,\n",
       " 'kavaler': 347904,\n",
       " 'sysoyev': 208757,\n",
       " 'dzhokar': 131007,\n",
       " 'goble': 93470,\n",
       " 'kavalek': 339352,\n",
       " 'sportscene': 337411,\n",
       " 'superhorse': 241600,\n",
       " 'gurongi': 393359,\n",
       " 'multipath': 131967,\n",
       " 'kavalee': 385972,\n",
       " 'ranidae': 112199,\n",
       " 'tula': 41581,\n",
       " 'tule': 74645,\n",
       " 'sÃ¼Ã\\x9f': 171425,\n",
       " 'tulf': 125971,\n",
       " 'tuli': 135286,\n",
       " 'tulk': 236597,\n",
       " 'tull': 52787,\n",
       " 'tulo': 199112,\n",
       " ...}"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word = {v: k for k, v in wordidx.items()}\n",
    "vocab_size=len(word_index)\n",
    "normal=np.random.normal\n",
    "emb = create_emb()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_dense_layer(model):\n",
    "    model.add(Dense(300))\n",
    "    model.add(PReLU())\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(BatchNormalization())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The first layer in a Sequential model must get an `input_shape` or `batch_input_shape` argument.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-249-521d1949e9e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0madd_dense_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0mmerged_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-238-a8dbe4d3708b>\u001b[0m in \u001b[0;36madd_dense_layer\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0madd_dense_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    288\u001b[0m                 \u001b[0;31m# create an input layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'batch_input_shape'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m                     raise ValueError('The first layer in a '\n\u001b[0m\u001b[1;32m    291\u001b[0m                                      \u001b[0;34m'Sequential model must '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m                                      \u001b[0;34m'get an `input_shape` or '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The first layer in a Sequential model must get an `input_shape` or `batch_input_shape` argument."
     ]
    }
   ],
   "source": [
    "#there is a thing here with the w2v: the author use nltk tokenizer which reduced number of words to 85K\n",
    "#therefore default emb_matrix should be 85K length. however, mine \n",
    "\n",
    "model = Sequential()\n",
    "print('Build model...')\n",
    "\n",
    "model1 = Sequential()\n",
    "model1.add(Embedding(vocab_size ,300, weights=[emb],input_length=40,trainable=False))\n",
    "\n",
    "model1.add(TimeDistributed(Dense(300, activation='relu')))\n",
    "model1.add(Lambda(lambda x: K.sum(x, axis=1), output_shape=(300,)))\n",
    "\n",
    "model2 = Sequential()\n",
    "model2.add(Embedding(vocab_size  ,300, weights=[emb], input_length=40,trainable=False))\n",
    "\n",
    "model2.add(TimeDistributed(Dense(300, activation='relu')))\n",
    "model2.add(Lambda(lambda x: K.sum(x, axis=1), output_shape=(300,)))\n",
    "\n",
    "model3 = Sequential()\n",
    "model3.add(Embedding(vocab_size  ,300,weights=[emb],input_length=40, trainable=False))\n",
    "model3.add(Convolution1D(nb_filter=nb_filter,filter_length=filter_length, border_mode='valid',\n",
    "                         activation='relu',subsample_length=1))\n",
    "model3.add(Dropout(0.2))\n",
    "\n",
    "model3.add(Convolution1D(nb_filter=nb_filter,filter_length=filter_length, border_mode='valid',activation='relu',\n",
    "                         subsample_length=1))\n",
    "\n",
    "model3.add(GlobalMaxPooling1D())\n",
    "model3.add(Dropout(0.2))\n",
    "\n",
    "model3.add(Dense(300))\n",
    "model3.add(Dropout(0.2))\n",
    "model3.add(BatchNormalization())\n",
    "\n",
    "model4 = Sequential()\n",
    "model4.add(Embedding(vocab_size,300, weights=[emb],input_length=40, trainable=False))\n",
    "model4.add(Convolution1D(nb_filter=nb_filter, filter_length=filter_length, border_mode='valid',\n",
    "                         activation='relu', subsample_length=1))\n",
    "model4.add(Dropout(0.2))\n",
    "\n",
    "model4.add(Convolution1D(nb_filter=nb_filter,filter_length=filter_length,border_mode='valid',  activation='relu',\n",
    "                         subsample_length=1))\n",
    "\n",
    "model4.add(GlobalMaxPooling1D())\n",
    "model4.add(Dropout(0.2))\n",
    "\n",
    "model4.add(Dense(300))\n",
    "model4.add(Dropout(0.2))\n",
    "model4.add(BatchNormalization())\n",
    "model5 = Sequential()\n",
    "model5.add(Embedding(vocab_size , 300, input_length=40, dropout=0.2))\n",
    "model5.add(LSTM(300, dropout_W=0.2, dropout_U=0.2))\n",
    "\n",
    "model6 = Sequential()\n",
    "model6.add(Embedding(vocab_size, 300, input_length=40, dropout=0.2))\n",
    "model6.add(LSTM(300, dropout_W=0.2, dropout_U=0.2))\n",
    "\n",
    "merged_model = Sequential()\n",
    "merged_model.add(Merge([model1, model2, model3, model4, model5, model6], mode='concat'))\n",
    "merged_model.add(BatchNormalization())\n",
    "\n",
    "\n",
    "for i in range(4):\n",
    "    add_dense_layer(model)\n",
    "\n",
    "merged_model.add(Dense(1))\n",
    "merged_model.add(Activation('sigmoid'))\n",
    "\n",
    "merged_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint('/mnt/quora_kaggle/results/abishek_weights.h5', monitor='val_loss'\\\n",
    "                             , save_best_only=True, verbose=2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "abi_model=merged_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2345796, 30)"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:91: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 363861 samples, validate on 40429 samples\n",
      "Epoch 1/200\n",
      "363648/363861 [============================>.] - ETA: 0s - loss: 0.5439 - acc: 0.7195Epoch 00000: val_loss improved from inf to 0.46335, saving model to /mnt/quora_kaggle/results/abishek_weights.h5\n",
      "363861/363861 [==============================] - 378s - loss: 0.5439 - acc: 0.7195 - val_loss: 0.4634 - val_acc: 0.7689\n",
      "Epoch 2/200\n",
      "363648/363861 [============================>.] - ETA: 0s - loss: 0.4472 - acc: 0.7840Epoch 00001: val_loss improved from 0.46335 to 0.45117, saving model to /mnt/quora_kaggle/results/abishek_weights.h5\n",
      "363861/363861 [==============================] - 372s - loss: 0.4472 - acc: 0.7839 - val_loss: 0.4512 - val_acc: 0.7815\n",
      "Epoch 3/200\n",
      "363648/363861 [============================>.] - ETA: 0s - loss: 0.3878 - acc: 0.8178Epoch 00002: val_loss improved from 0.45117 to 0.42211, saving model to /mnt/quora_kaggle/results/abishek_weights.h5\n",
      "363861/363861 [==============================] - 372s - loss: 0.3878 - acc: 0.8177 - val_loss: 0.4221 - val_acc: 0.8008\n",
      "Epoch 4/200\n",
      "363648/363861 [============================>.] - ETA: 0s - loss: 0.3363 - acc: 0.8457Epoch 00003: val_loss did not improve\n",
      "363861/363861 [==============================] - 370s - loss: 0.3364 - acc: 0.8457 - val_loss: 0.4319 - val_acc: 0.7956\n",
      "Epoch 5/200\n",
      "363648/363861 [============================>.] - ETA: 0s - loss: 0.2978 - acc: 0.8654Epoch 00004: val_loss did not improve\n",
      "363861/363861 [==============================] - 370s - loss: 0.2978 - acc: 0.8654 - val_loss: 0.4427 - val_acc: 0.8039\n",
      "Epoch 6/200\n",
      "363648/363861 [============================>.] - ETA: 0s - loss: 0.2668 - acc: 0.8809Epoch 00005: val_loss did not improve\n",
      "363861/363861 [==============================] - 370s - loss: 0.2669 - acc: 0.8809 - val_loss: 0.4675 - val_acc: 0.8038\n",
      "Epoch 7/200\n",
      " 17664/363861 [>.............................] - ETA: 344s - loss: 0.2271 - acc: 0.8999"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-230-33642741eedb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m merged_model.fit([x1, x2, x1, x2, x1, x2], y=y, batch_size=384, nb_epoch=200,\n\u001b[0;32m----> 2\u001b[0;31m                  verbose=1, validation_split=0.1, shuffle=True, callbacks=[checkpoint,early_stopping])\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    670\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 672\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    674\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch)\u001b[0m\n\u001b[1;32m   1194\u001b[0m                               \u001b[0mval_f\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_f\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_ins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m                               \u001b[0mcallback_metrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallback_metrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1196\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1198\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, nb_epoch, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m                 \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   1941\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1942\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 1943\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   1944\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1945\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "merged_model.fit([x1, x2, x1, x2, x1, x2], y=y, batch_size=384, nb_epoch=200,\n",
    "                 verbose=1, validation_split=0.1, shuffle=True, callbacks=[checkpoint,early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90750204061441042"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y,np.round(abi_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "abi_preds=merged_model.predict([x1, x2, x1, x2, x1, x2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Level 2 Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combined LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "import tqdm\n",
    "from scipy.spatial.distance import cosine, cityblock, jaccard, canberra, euclidean, minkowski, braycurtis\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def sent2vec(s):\n",
    "    words = str(s).lower()#.decode('utf-8')\n",
    "    words = word_tokenize(words)\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    words = [w for w in words if w.isalpha()]\n",
    "    M = []\n",
    "    for w in words:\n",
    "        try:\n",
    "            M.append(w2v[w])\n",
    "        except:\n",
    "            continue\n",
    "    M = np.array(M)\n",
    "    v = M.sum(axis=0)\n",
    "    return v / np.sqrt((v ** 2).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "    words = str(s).lower()#.decode('utf-8')\n",
    "    words = word_tokenize(words)\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    words = [w for w in words if w.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n",
      "\n",
      "538it [00:00, 5375.47it/s]\u001b[A\n",
      "1079it [00:00, 5383.88it/s]\u001b[A\n",
      "1617it [00:00, 5381.98it/s]\u001b[A\n",
      "2156it [00:00, 5382.77it/s]\u001b[A\n",
      "2711it [00:00, 5429.73it/s]\u001b[A\n",
      "3260it [00:00, 5445.77it/s]\u001b[A\n",
      "3812it [00:00, 5467.35it/s]\u001b[A\n",
      "4358it [00:00, 5463.56it/s]\u001b[A\n",
      "4878it [00:00, 5381.56it/s]\u001b[A\n",
      "5431it [00:01, 5422.80it/s]\u001b[A\n",
      "5973it [00:01, 5420.54it/s]\u001b[A\n",
      "6534it [00:01, 5474.87it/s]\u001b[A\n",
      "7089it [00:01, 5494.73it/s]\u001b[A\n",
      "7634it [00:01, 5479.96it/s]\u001b[A\n",
      "8180it [00:01, 5470.68it/s]\u001b[A\n",
      "8732it [00:01, 5483.37it/s]\u001b[A\n",
      "9285it [00:01, 5494.83it/s]\u001b[A\n",
      "9834it [00:01, 5492.30it/s]\u001b[A\n",
      "10383it [00:01, 5424.76it/s]\u001b[A\n",
      "10930it [00:02, 5435.60it/s]\u001b[A\n",
      "11477it [00:02, 5445.71it/s]\u001b[A\n",
      "12022it [00:02, 5433.57it/s]\u001b[A\n",
      "12568it [00:02, 5439.22it/s]\u001b[A\n",
      "13124it [00:02, 5472.81it/s]\u001b[A\n",
      "13672it [00:02, 5471.27it/s]\u001b[A\n",
      "14224it [00:02, 5484.35it/s]\u001b[A\n",
      "14773it [00:02, 5479.43it/s]\u001b[A\n",
      "15321it [00:02, 5461.83it/s]\u001b[A\n",
      "15868it [00:02, 5434.33it/s]\u001b[A\n",
      "16415it [00:03, 5442.96it/s]\u001b[A\n",
      "16960it [00:03, 5440.24it/s]\u001b[A\n",
      "17505it [00:03, 5378.86it/s]\u001b[A\n",
      "18060it [00:03, 5425.75it/s]\u001b[A\n",
      "18613it [00:03, 5456.07it/s]\u001b[A\n",
      "19159it [00:03, 5456.10it/s]\u001b[A\n",
      "19705it [00:03, 5453.31it/s]\u001b[A\n",
      "20251it [00:03, 5454.22it/s]\u001b[A\n",
      "20797it [00:03, 4536.10it/s]\u001b[A\n",
      "21340it [00:03, 4771.69it/s]\u001b[A\n",
      "21863it [00:04, 4898.04it/s]\u001b[A\n",
      "22369it [00:04, 4942.80it/s]\u001b[A\n",
      "22894it [00:04, 5028.16it/s]\u001b[A\n",
      "23405it [00:04, 5033.73it/s]\u001b[A\n",
      "23942it [00:04, 5129.37it/s]\u001b[A\n",
      "24490it [00:04, 5226.77it/s]\u001b[A\n",
      "25047it [00:04, 5322.28it/s]\u001b[A\n",
      "25594it [00:04, 5365.53it/s]\u001b[A\n",
      "26134it [00:04, 5374.41it/s]\u001b[A\n",
      "26673it [00:04, 5356.17it/s]\u001b[A\n",
      "27213it [00:05, 5366.10it/s]\u001b[A\n",
      "27751it [00:05, 5319.59it/s]\u001b[A\n",
      "28289it [00:05, 5337.06it/s]\u001b[A\n",
      "28842it [00:05, 5390.93it/s]\u001b[A\n",
      "29382it [00:05, 5299.78it/s]\u001b[A\n",
      "29930it [00:05, 5348.37it/s]\u001b[A\n",
      "30466it [00:05, 5333.13it/s]\u001b[A\n",
      "31000it [00:05, 5280.53it/s]\u001b[A\n",
      "31529it [00:05, 5144.04it/s]\u001b[A\n",
      "32045it [00:06, 5116.56it/s]\u001b[A\n",
      "32558it [00:06, 5084.82it/s]\u001b[A\n",
      "33070it [00:06, 5092.26it/s]\u001b[A\n",
      "33606it [00:06, 5168.08it/s]\u001b[A\n",
      "34157it [00:06, 5264.97it/s]\u001b[A\n",
      "34704it [00:06, 5322.87it/s]\u001b[A\n",
      "35259it [00:06, 5388.33it/s]\u001b[A\n",
      "35813it [00:06, 5432.68it/s]\u001b[A\n",
      "36364it [00:06, 5454.70it/s]\u001b[A\n",
      "36910it [00:06, 5431.12it/s]\u001b[A\n",
      "37464it [00:07, 5460.96it/s]\u001b[A\n",
      "38011it [00:07, 5457.13it/s]\u001b[A\n",
      "38564it [00:07, 5477.57it/s]\u001b[A\n",
      "39112it [00:07, 5476.81it/s]\u001b[A\n",
      "39662it [00:07, 5481.66it/s]\u001b[A\n",
      "40211it [00:07, 5482.59it/s]\u001b[A\n",
      "40760it [00:07, 5484.31it/s]\u001b[A\n",
      "41309it [00:07, 5483.51it/s]\u001b[A\n",
      "41858it [00:07, 5476.97it/s]\u001b[A\n",
      "42406it [00:07, 5441.42it/s]\u001b[A\n",
      "42951it [00:08, 5428.98it/s]\u001b[A\n",
      "43503it [00:08, 5454.23it/s]\u001b[A\n",
      "44052it [00:08, 5463.17it/s]\u001b[A\n",
      "44602it [00:08, 5473.62it/s]\u001b[A\n",
      "45150it [00:08, 5465.59it/s]\u001b[A\n",
      "45697it [00:08, 5448.86it/s]\u001b[A\n",
      "46242it [00:08, 5425.27it/s]\u001b[A\n",
      "46785it [00:08, 5407.51it/s]\u001b[A\n",
      "47326it [00:08, 4492.93it/s]\u001b[A\n",
      "47869it [00:08, 4737.69it/s]\u001b[A\n",
      "48416it [00:09, 4934.64it/s]\u001b[A\n",
      "48950it [00:09, 5047.92it/s]\u001b[A\n",
      "\n",
      "404290it [01:15, 5349.29it/s]\n",
      "404290it [01:16, 5293.88it/s]\n"
     ]
    }
   ],
   "source": [
    "question1_vectors = np.zeros((data.shape[0], 300))\n",
    "error_count = 0\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "for i, q in tqdm.tqdm(enumerate(data.question1.values)):\n",
    "    question1_vectors[i, :] = sent2vec(q)\n",
    "\n",
    "question2_vectors  = np.zeros((data.shape[0], 300))\n",
    "for i, q in tqdm.tqdm(enumerate(data.question2.values)):\n",
    "    question2_vectors[i, :] = sent2vec(q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "       [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "       [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "       ..., \n",
       "       [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "       [ nan,  nan,  nan, ...,  nan,  nan,  nan],\n",
       "       [ nan,  nan,  nan, ...,  nan,  nan,  nan]])"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question1_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "727722/727722 [==============================] - 55s    \n",
      "727722/727722 [==============================] - 55s    \n"
     ]
    }
   ],
   "source": [
    "preds_trn = model.predict([data_1_train, data_2_train], batch_size=8192, verbose=1)\n",
    "preds_trn += model.predict([data_2_train, data_1_train], batch_size=8192, verbose=1)\n",
    "preds_trn /= 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80858/80858 [==============================] - 6s     \n",
      "80858/80858 [==============================] - 6s     \n"
     ]
    }
   ],
   "source": [
    "preds_val = model.predict([data_1_val, data_2_val], batch_size=8192, verbose=1)\n",
    "preds_val += model.predict([data_2_val, data_1_val], batch_size=8192, verbose=1)\n",
    "preds_val /= 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### do xgboost, first only on length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "len_q1 = pd.Series(texts_1).apply(lambda x: len(str(x)))\n",
    "len_q2 = pd.Series(texts_2).apply(lambda x: len(str(x)))\n",
    "diff_len = len_q1 - len_q2\n",
    "len_char_q1 = pd.Series(texts_1).apply(lambda x: len(''.join(set(str(x).replace(' ', '')))))\n",
    "len_char_q2 = pd.Series(texts_2).apply(lambda x: len(''.join(set(str(x).replace(' ', '')))))#.61 until here\n",
    "len_word_q1 = pd.Series(texts_1).apply(lambda x: len(str(x).split()))\n",
    "len_word_q2 = pd.Series(texts_2).apply(lambda x: len(str(x).split())) #.59 until here\n",
    "common_words = data.apply(lambda x: len(set(str(x['question1']).lower().split()).intersection(set(str(x['question2']).lower().split()))), axis=1)\n",
    "#down to 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'acc': [0.66837198818970756,\n",
       "  0.71693036624903883,\n",
       "  0.74021398281277306,\n",
       "  0.75507680131926191,\n",
       "  0.76700031050163775,\n",
       "  0.77608482363576803,\n",
       "  0.78318781069912502,\n",
       "  0.78978785855971778,\n",
       "  0.79588634128970726,\n",
       "  0.80016544780658316,\n",
       "  0.80378908435444341,\n",
       "  0.8070815503427714,\n",
       "  0.80944096790993347,\n",
       "  0.81196940593849276,\n",
       "  0.81417354434117362],\n",
       " 'loss': [0.43087042183261626,\n",
       "  0.35572124865343258,\n",
       "  0.33113729155331856,\n",
       "  0.31463765397883586,\n",
       "  0.30252043344387081,\n",
       "  0.29297803798897532,\n",
       "  0.28553758301474291,\n",
       "  0.27866757922398006,\n",
       "  0.27253165002420082,\n",
       "  0.26796472785263592,\n",
       "  0.26437277323537006,\n",
       "  0.26079637268015798,\n",
       "  0.25824614342470531,\n",
       "  0.25541665385506629,\n",
       "  0.25331244394861546],\n",
       " 'val_acc': [0.6782012905759377,\n",
       "  0.75032773483527537,\n",
       "  0.76729575288785512,\n",
       "  0.78694748801078029,\n",
       "  0.78997749110982396,\n",
       "  0.80067525794201833,\n",
       "  0.79702688588003667,\n",
       "  0.80877587899874193,\n",
       "  0.81188008633925224,\n",
       "  0.8135002106063256,\n",
       "  0.81625813137117098,\n",
       "  0.82098246281658116,\n",
       "  0.82482871176089068,\n",
       "  0.82215736220246172,\n",
       "  0.8222810361348134],\n",
       " 'val_loss': [0.36818972082895735,\n",
       "  0.33744397210038096,\n",
       "  0.31824305196832642,\n",
       "  0.31171486930152592,\n",
       "  0.30231716275088361,\n",
       "  0.29896242199814166,\n",
       "  0.29153288116338077,\n",
       "  0.29152453314875004,\n",
       "  0.29162282392807592,\n",
       "  0.29001342648463679,\n",
       "  0.28987959426826782,\n",
       "  0.29479447059443342,\n",
       "  0.29378388792113475,\n",
       "  0.29042628707941531,\n",
       "  0.29049098058002121]}"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data=pd.DataFrame({\"question1\":texts_1,\"question2\":texts_2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "data['fuzz_partial_ratio'] = data.apply(lambda x: fuzz.partial_ratio(str(x['question1']), str(x['question2'])), axis=1)\n",
    "data['fuzz_partial_token_set_ratio'] = data.apply(lambda x: fuzz.partial_token_set_ratio(str(x['question1']), str(x['question2'])), axis=1)\n",
    "#50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/fuzzywuzzy/fuzz.py:35: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-173-243531c451af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfuzz_qratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfuzz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQRatio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'question1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'question2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, broadcast, raw, reduce, args, **kwds)\u001b[0m\n\u001b[1;32m   4150\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4151\u001b[0m                         \u001b[0mreduce\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4152\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4153\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4154\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_broadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m_apply_standard\u001b[0;34m(self, func, axis, ignore_failures, reduce)\u001b[0m\n\u001b[1;32m   4206\u001b[0m                     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_agg_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4207\u001b[0m                     result = lib.reduce(values, func, axis=axis, dummy=dummy,\n\u001b[0;32m-> 4208\u001b[0;31m                                         labels=labels)\n\u001b[0m\u001b[1;32m   4209\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4210\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/src/reduce.pyx\u001b[0m in \u001b[0;36mpandas.lib.reduce (pandas/lib.c:45030)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/src/reduce.pyx\u001b[0m in \u001b[0;36mpandas.lib.Reducer.get_result (pandas/lib.c:34673)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-173-243531c451af>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfuzz_qratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mfuzz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mQRatio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'question1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'question2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/fuzzywuzzy/fuzz.py\u001b[0m in \u001b[0;36mQRatio\u001b[0;34m(s1, s2, force_ascii)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mratio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/fuzzywuzzy/utils.py\u001b[0m in \u001b[0;36mdecorator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/fuzzywuzzy/utils.py\u001b[0m in \u001b[0;36mdecorator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/site-packages/fuzzywuzzy/fuzz.py\u001b[0m in \u001b[0;36mratio\u001b[0;34m(s1, s2)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSequenceMatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/difflib.py\u001b[0m in \u001b[0;36mratio\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    642\u001b[0m         \"\"\"\n\u001b[1;32m    643\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m         \u001b[0mmatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtriple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtriple\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_matching_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_calculate_ratio\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmatches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/difflib.py\u001b[0m in \u001b[0;36mget_matching_blocks\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    477\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m             \u001b[0malo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mahi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbhi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqueue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m             \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind_longest_match\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mahi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbhi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m             \u001b[0;31m# a[alo:i] vs b[blo:j] unknown\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m             \u001b[0;31m# a[i:i+k] same as b[j:j+k]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/anaconda3/lib/python3.6/difflib.py\u001b[0m in \u001b[0;36mfind_longest_match\u001b[0;34m(self, alo, ahi, blo, bhi)\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0mj2lenget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mj2len\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    403\u001b[0m             \u001b[0mnewj2len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mb2j\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m                 \u001b[0;31m# a[i] matches b[j]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mj\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mblo\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "fuzz_qratio = data.apply(lambda x: fuzz.QRatio(str(x['question1']), str(x['question2'])), axis=1)\n",
    "#slowish\n",
    "#15:38\n",
    "fuzz_WRatio = data.apply(lambda x: fuzz.WRatio(str(x['question1']), str(x['question2'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-145-d0f07c136ebb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'len_q1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquestion1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'len_q2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquestion2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'diff_len'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlen_q1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlen_q2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'len_char_q1'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquestion1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'len_char_q2'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquestion2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "data['fuzz_partial_token_sort_ratio'] = data.apply(lambda x: fuzz.partial_token_sort_ratio(str(x['question1']), str(x['question2'])), axis=1)\n",
    "data['fuzz_token_set_ratio'] = data.apply(lambda x: fuzz.token_set_ratio(str(x['question1']), str(x['question2'])), axis=1)\n",
    "data['fuzz_token_sort_ratio'] = data.apply(lambda x: fuzz.token_sort_ratio(str(x['question1']), str(x['question2'])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method Booster.__del__ of <xgboost.core.Booster object at 0x7f5652e40978>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/xgboost/core.py\", line 656, in __del__\n",
      "    _LIB.XGBoosterFree(self.handle)\n",
      "AttributeError: 'Booster' object has no attribute 'handle'\n"
     ]
    }
   ],
   "source": [
    "lens=[[len(x1),len(x2)] for x1,x2 in zip(sequences_1,sequences_2)]\n",
    "lens_diff=[[len(x1)-len(x2)] for x1,x2 in zip(sequences_1,sequences_2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lens=np.array(lens)\n",
    "lens_diff=np.array(lens_diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404290, 1)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens_diff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xgb_train=np.vstack([len_q1.T,len_q2.T,diff_len.T,len_char_q1.T,len_char_q2.T,len_word_q1.T,len_word_q2.T,\\\n",
    "                    common_words.T,data['fuzz_partial_ratio'].T,data['fuzz_partial_token_set_ratio'].T]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "xgb_train=np.vstack([lens.T,lens_diff.T]).T[idx_train]\n",
    "xgb_val=np.vstack([lens.T,lens_diff.T]).T[idx_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(363861, 2)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y_train=labels[idx_train]\n",
    "y_val=labels[idx_val]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.688401\n",
      "Will train until train-logloss hasn't improved in 50 rounds.\n",
      "[10]\ttrain-logloss:0.649606\n",
      "[20]\ttrain-logloss:0.622312\n",
      "[30]\ttrain-logloss:0.602355\n",
      "[40]\ttrain-logloss:0.587363\n",
      "[50]\ttrain-logloss:0.575881\n",
      "[60]\ttrain-logloss:0.567014\n",
      "[70]\ttrain-logloss:0.560045\n",
      "[80]\ttrain-logloss:0.554515\n",
      "[90]\ttrain-logloss:0.550027\n",
      "[100]\ttrain-logloss:0.546349\n",
      "[110]\ttrain-logloss:0.54337\n",
      "[120]\ttrain-logloss:0.540882\n",
      "[130]\ttrain-logloss:0.538731\n",
      "[140]\ttrain-logloss:0.536916\n",
      "[150]\ttrain-logloss:0.535325\n",
      "[160]\ttrain-logloss:0.534012\n",
      "[170]\ttrain-logloss:0.532795\n",
      "[180]\ttrain-logloss:0.531731\n",
      "[190]\ttrain-logloss:0.530754\n",
      "[200]\ttrain-logloss:0.529972\n",
      "[210]\ttrain-logloss:0.529249\n",
      "[220]\ttrain-logloss:0.528646\n",
      "[230]\ttrain-logloss:0.528064\n",
      "[240]\ttrain-logloss:0.527571\n",
      "[250]\ttrain-logloss:0.527082\n",
      "[260]\ttrain-logloss:0.526511\n",
      "[270]\ttrain-logloss:0.525945\n",
      "[280]\ttrain-logloss:0.525371\n",
      "[290]\ttrain-logloss:0.524833\n",
      "[300]\ttrain-logloss:0.524356\n",
      "[310]\ttrain-logloss:0.523976\n",
      "[320]\ttrain-logloss:0.523637\n",
      "[330]\ttrain-logloss:0.523228\n",
      "[340]\ttrain-logloss:0.522842\n",
      "[350]\ttrain-logloss:0.522481\n",
      "[360]\ttrain-logloss:0.52205\n",
      "[370]\ttrain-logloss:0.521721\n",
      "[380]\ttrain-logloss:0.521327\n",
      "[390]\ttrain-logloss:0.520927\n",
      "[400]\ttrain-logloss:0.520596\n",
      "[410]\ttrain-logloss:0.520241\n",
      "[420]\ttrain-logloss:0.519833\n",
      "[430]\ttrain-logloss:0.519486\n",
      "[440]\ttrain-logloss:0.519179\n",
      "[450]\ttrain-logloss:0.518885\n",
      "[460]\ttrain-logloss:0.518595\n",
      "[470]\ttrain-logloss:0.518258\n",
      "[480]\ttrain-logloss:0.518017\n",
      "[490]\ttrain-logloss:0.517711\n",
      "[500]\ttrain-logloss:0.517443\n",
      "[510]\ttrain-logloss:0.517218\n",
      "[520]\ttrain-logloss:0.516996\n",
      "[530]\ttrain-logloss:0.516648\n",
      "[540]\ttrain-logloss:0.516321\n",
      "[550]\ttrain-logloss:0.516043\n",
      "[560]\ttrain-logloss:0.515837\n",
      "[570]\ttrain-logloss:0.515615\n",
      "[580]\ttrain-logloss:0.515388\n",
      "[590]\ttrain-logloss:0.515068\n",
      "[600]\ttrain-logloss:0.514896\n",
      "[610]\ttrain-logloss:0.514652\n",
      "[620]\ttrain-logloss:0.514418\n",
      "[630]\ttrain-logloss:0.51418\n",
      "[640]\ttrain-logloss:0.513939\n",
      "[650]\ttrain-logloss:0.513762\n",
      "[660]\ttrain-logloss:0.51354\n",
      "[670]\ttrain-logloss:0.513285\n",
      "[680]\ttrain-logloss:0.513083\n",
      "[690]\ttrain-logloss:0.512929\n",
      "[700]\ttrain-logloss:0.512689\n",
      "[710]\ttrain-logloss:0.512569\n",
      "[720]\ttrain-logloss:0.512393\n",
      "[730]\ttrain-logloss:0.512197\n",
      "[740]\ttrain-logloss:0.512021\n",
      "[750]\ttrain-logloss:0.511795\n",
      "[760]\ttrain-logloss:0.511592\n",
      "[770]\ttrain-logloss:0.511366\n",
      "[780]\ttrain-logloss:0.511162\n",
      "[790]\ttrain-logloss:0.510977\n",
      "[800]\ttrain-logloss:0.510763\n",
      "[810]\ttrain-logloss:0.510623\n",
      "[820]\ttrain-logloss:0.510433\n",
      "[830]\ttrain-logloss:0.510244\n",
      "[840]\ttrain-logloss:0.510108\n",
      "[850]\ttrain-logloss:0.509929\n",
      "[860]\ttrain-logloss:0.509736\n",
      "[870]\ttrain-logloss:0.509571\n",
      "[880]\ttrain-logloss:0.509409\n",
      "[890]\ttrain-logloss:0.509265\n",
      "[900]\ttrain-logloss:0.509121\n",
      "[910]\ttrain-logloss:0.508901\n",
      "[920]\ttrain-logloss:0.508732\n",
      "[930]\ttrain-logloss:0.508563\n",
      "[940]\ttrain-logloss:0.508383\n",
      "[950]\ttrain-logloss:0.508234\n",
      "[960]\ttrain-logloss:0.508078\n",
      "[970]\ttrain-logloss:0.507925\n",
      "[980]\ttrain-logloss:0.507823\n",
      "[990]\ttrain-logloss:0.50767\n",
      "[1000]\ttrain-logloss:0.507571\n",
      "[1010]\ttrain-logloss:0.507424\n",
      "[1020]\ttrain-logloss:0.507291\n",
      "[1030]\ttrain-logloss:0.507178\n",
      "[1040]\ttrain-logloss:0.507073\n",
      "[1050]\ttrain-logloss:0.506909\n",
      "[1060]\ttrain-logloss:0.506777\n",
      "[1070]\ttrain-logloss:0.506632\n",
      "[1080]\ttrain-logloss:0.506506\n",
      "[1090]\ttrain-logloss:0.506386\n",
      "[1100]\ttrain-logloss:0.506271\n",
      "[1110]\ttrain-logloss:0.506136\n",
      "[1120]\ttrain-logloss:0.506002\n",
      "[1130]\ttrain-logloss:0.505859\n",
      "[1140]\ttrain-logloss:0.505736\n",
      "[1150]\ttrain-logloss:0.505593\n",
      "[1160]\ttrain-logloss:0.505507\n",
      "[1170]\ttrain-logloss:0.505419\n",
      "[1180]\ttrain-logloss:0.505308\n",
      "[1190]\ttrain-logloss:0.505169\n",
      "[1200]\ttrain-logloss:0.50506\n",
      "[1210]\ttrain-logloss:0.5049\n",
      "[1220]\ttrain-logloss:0.504811\n",
      "[1230]\ttrain-logloss:0.504705\n",
      "[1240]\ttrain-logloss:0.504593\n",
      "[1250]\ttrain-logloss:0.504497\n",
      "[1260]\ttrain-logloss:0.504411\n",
      "[1270]\ttrain-logloss:0.504309\n",
      "[1280]\ttrain-logloss:0.504167\n",
      "[1290]\ttrain-logloss:0.50409\n",
      "[1300]\ttrain-logloss:0.503982\n",
      "[1310]\ttrain-logloss:0.503857\n",
      "[1320]\ttrain-logloss:0.503739\n",
      "[1330]\ttrain-logloss:0.503665\n",
      "[1340]\ttrain-logloss:0.503602\n",
      "[1350]\ttrain-logloss:0.50353\n",
      "[1360]\ttrain-logloss:0.503464\n",
      "[1370]\ttrain-logloss:0.503386\n",
      "[1380]\ttrain-logloss:0.503286\n",
      "[1390]\ttrain-logloss:0.503228\n",
      "[1400]\ttrain-logloss:0.503165\n",
      "[1410]\ttrain-logloss:0.503071\n",
      "[1420]\ttrain-logloss:0.502998\n",
      "[1430]\ttrain-logloss:0.50293\n",
      "[1440]\ttrain-logloss:0.502854\n",
      "[1450]\ttrain-logloss:0.502787\n",
      "[1460]\ttrain-logloss:0.502741\n",
      "[1470]\ttrain-logloss:0.502643\n",
      "[1480]\ttrain-logloss:0.502539\n",
      "[1490]\ttrain-logloss:0.502425\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "# Set our parameters for xgboost\n",
    "params = {'objective':'binary:logistic','eval_metric':'logloss','eta':0.02,'max_depth':4}\n",
    "\n",
    "d_train = xgb.DMatrix(xgb_train, label=labels)\n",
    "#d_valid = xgb.DMatrix(xgb_val, label=y_val)\n",
    "\n",
    "watchlist = [(d_train, 'train') ]#, (d_valid, 'valid')]\n",
    "\n",
    "bst = xgb.train(params, d_train, 1500, watchlist, early_stopping_rounds=50, verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true,
    "hidden": true
   },
   "outputs": [],
   "source": [
    "p_train_l1 = bst.predict(d_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "p_val_l1 = bst.predict(d_valid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### second level xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00336859,  0.36761916,  0.93248445, ...,  0.00658101,\n",
       "        0.61697412,  0.01418427], dtype=float32)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_trn[:363861,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "level_2_trn=np.vstack([preds_trn[:363861,0],preds_trn[363861:,0]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "level_2_val=np.vstack([preds_val[:40429,0],preds_val[40429:,0]]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80858,), (80858,))"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_val.shape,preds_val[:,0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, ..., 0, 1, 0]),\n",
       " array([ 0.04384141,  0.09105706,  0.26341006, ...,  0.32462829,\n",
       "         0.70351142,  0.77972245], dtype=float32))"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_val,preds_val[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80832/80858 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.39598954485238164, 0.81625813155988192]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([data_1_val, data_2_val], labels_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1662: RuntimeWarning: divide by zero encountered in log\n",
      "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1662: RuntimeWarning: invalid value encountered in multiply\n",
      "  loss = -(transformed_labels * np.log(y_pred)).sum(axis=1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "nan"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(labels_val[:8000],preds_val[:8000,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.680137\tvalid-logloss:0.681765\n",
      "Multiple eval metrics have been passed: 'valid-logloss' will be used for early stopping.\n",
      "\n",
      "Will train until valid-logloss hasn't improved in 50 rounds.\n",
      "[10]\ttrain-logloss:0.574113\tvalid-logloss:0.590256\n",
      "[20]\ttrain-logloss:0.49948\tvalid-logloss:0.527672\n",
      "[30]\ttrain-logloss:0.445204\tvalid-logloss:0.483735\n",
      "[40]\ttrain-logloss:0.404894\tvalid-logloss:0.452482\n",
      "[50]\ttrain-logloss:0.374534\tvalid-logloss:0.430131\n",
      "[60]\ttrain-logloss:0.351445\tvalid-logloss:0.414182\n",
      "[70]\ttrain-logloss:0.333765\tvalid-logloss:0.402911\n",
      "[80]\ttrain-logloss:0.320168\tvalid-logloss:0.395091\n",
      "[90]\ttrain-logloss:0.309681\tvalid-logloss:0.389828\n",
      "[100]\ttrain-logloss:0.301576\tvalid-logloss:0.38644\n",
      "[110]\ttrain-logloss:0.295303\tvalid-logloss:0.384415\n",
      "[120]\ttrain-logloss:0.290446\tvalid-logloss:0.383371\n",
      "[130]\ttrain-logloss:0.286683\tvalid-logloss:0.383052\n",
      "[140]\ttrain-logloss:0.28377\tvalid-logloss:0.38322\n",
      "[150]\ttrain-logloss:0.281513\tvalid-logloss:0.383756\n",
      "[160]\ttrain-logloss:0.279768\tvalid-logloss:0.384518\n",
      "[170]\ttrain-logloss:0.278421\tvalid-logloss:0.38538\n",
      "[180]\ttrain-logloss:0.277381\tvalid-logloss:0.386305\n",
      "Stopping. Best iteration:\n",
      "[130]\ttrain-logloss:0.286683\tvalid-logloss:0.383052\n",
      "\n"
     ]
    }
   ],
   "source": [
    "params = {'objective':'binary:logistic','eval_metric':'logloss','eta':0.02,'max_depth':4}\n",
    "\n",
    "d_train = xgb.DMatrix(level_2_trn, label=y_train)\n",
    "d_valid = xgb.DMatrix(level_2_val, label=y_val)\n",
    "\n",
    "watchlist = [(d_train, 'train') , (d_valid, 'valid')]\n",
    "\n",
    "bst_level2 = xgb.train(params, d_train, 1500, watchlist, early_stopping_rounds=50, verbose_eval=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
